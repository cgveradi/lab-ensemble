{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "# 1. Clean missing values\n",
    "spaceship_clean = spaceship.dropna().copy()\n",
    "\n",
    "# 2. Cabin Transformation (Cardinality Reduction)\n",
    "# Extract the 'Deck' from the Cabin string (e.g., 'B/0/P' -> 'B')\n",
    "spaceship_clean['Cabin_Deck'] = spaceship_clean['Cabin'].str[0]\n",
    "\n",
    "# 3. Create Total Spending Feature (Aggregation)\n",
    "spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "spaceship_clean['Total_Spent'] = spaceship_clean[spending_cols].sum(axis=1)\n",
    "\n",
    "# 4. Feature Selection: Drop non-predictive IDs and original Cabin string\n",
    "spaceship_clean = spaceship_clean.drop(['PassengerId', 'Name', 'Cabin'], axis=1)\n",
    "\n",
    "# 5. Encoding Categorical Variables\n",
    "# Convert HomePlanet, CryoSleep, Destination, VIP, and Cabin_Deck into dummies\n",
    "spaceship_final = pd.get_dummies(spaceship_clean, drop_first=True)\n",
    "\n",
    "# 6. Target Conversion\n",
    "spaceship_final['Transported'] = spaceship_final['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spaceship_final.drop(['Transported'], axis=1)\n",
    "y = spaceship_final['Transported'].astype(int)\n",
    "\n",
    "# 2. Stratified Split (The \"Fair\" Comparison)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Scaling (Essential for Gradient Boosting stability)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7753\n",
      "Pasting Accuracy: 0.7602\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Initialize the \"Base Expert\" (usually a Decision Tree)\n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2. BAGGING (bootstrap=True)\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=base_estimator, \n",
    "    n_estimators=100, \n",
    "    bootstrap=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. PASTING (bootstrap=False)\n",
    "pasting_model = BaggingClassifier(\n",
    "    estimator=base_estimator, \n",
    "    n_estimators=100, \n",
    "    bootstrap=False, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Train and Evaluate\n",
    "bagging_model.fit(X_train_scaled, y_train)\n",
    "pasting_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Bagging Accuracy: {accuracy_score(y_test, bagging_model.predict(X_test_scaled)):.4f}\")\n",
    "print(f\"Pasting Accuracy: {accuracy_score(y_test, pasting_model.predict(X_test_scaled)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7708\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       656\n",
      "           1       0.77      0.77      0.77       666\n",
      "\n",
      "    accuracy                           0.77      1322\n",
      "   macro avg       0.77      0.77      0.77      1322\n",
      "weighted avg       0.77      0.77      0.77      1322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Initialize the Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2. Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. Predict and Evaluate\n",
    "rf_preds = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_preds):.4f}\")\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.7844\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       656\n",
      "           1       0.76      0.84      0.80       666\n",
      "\n",
      "    accuracy                           0.78      1322\n",
      "   macro avg       0.79      0.78      0.78      1322\n",
      "weighted avg       0.79      0.78      0.78      1322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Initialize the Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train the model\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. Predict and Evaluate\n",
    "gb_preds = gb_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_score(y_test, gb_preds):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, gb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.7829\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Initialize the base \"Stub\" (optional, but good for control)\n",
    "base_stub = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# 2. Initialize AdaBoost\n",
    "ada_model = AdaBoostClassifier(\n",
    "    estimator=base_stub, \n",
    "    n_estimators=100, \n",
    "    learning_rate=1.0, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Train and Predict\n",
    "ada_model.fit(X_train_scaled, y_train)\n",
    "ada_preds = ada_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"AdaBoost Accuracy: {accuracy_score(y_test, ada_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Accuracy\n",
      "Gradient Boosting  0.784418\n",
      "AdaBoost           0.782905\n",
      "Bagging            0.775340\n",
      "Random Forest      0.770802\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Comparing all results\n",
    "final_comparison = {\n",
    "    \"Bagging\": accuracy_score(y_test, bagging_model.predict(X_test_scaled)),\n",
    "    \"Random Forest\": accuracy_score(y_test, rf_model.predict(X_test_scaled)),\n",
    "    \"Gradient Boosting\": accuracy_score(y_test, gb_model.predict(X_test_scaled)),\n",
    "    \"AdaBoost\": accuracy_score(y_test, ada_preds)\n",
    "}\n",
    "\n",
    "\n",
    "comparison_df = pd.DataFrame.from_dict(final_comparison, orient='index', columns=['Accuracy'])\n",
    "print(comparison_df.sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ensemble methods, particularly Ada Boosting and Gradient Boosting, outperform the basic Bagging and Random Forest models. This highlights the effectiveness of combining multiple weak learners to create a robust predictive model.\n"
     ]
    }
   ],
   "source": [
    "#comment here\n",
    "print (\"The ensemble methods, particularly Ada Boosting and Gradient Boosting, outperform the basic Bagging and Random Forest models. This highlights the effectiveness of combining multiple weak learners to create a robust predictive model.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
